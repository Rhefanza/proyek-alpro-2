{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7659d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing is a crucial step in any computer vision or machine learning project involving images. It involves applying a series of transformations to raw images to make them more suitable for analysis, enhance their features, reduce noise, and standardize them for a model.\n",
      "\n",
      "The goal of image preprocessing is to:\n",
      "1.  **Improve Data Quality:** Remove noise, correct distortions, and enhance relevant features.\n",
      "2.  **Standardize Data:** Ensure all images have consistent dimensions, color space, and pixel value ranges.\n",
      "3.  **Reduce Dimensionality:** Sometimes simplify images (e.g., grayscale) to speed up processing.\n",
      "4.  **Enhance Model Performance:** Provide cleaner, more consistent data that helps models learn more effectively and generalize better.\n",
      "\n",
      "Here's a breakdown of common image preprocessing techniques, why they are used, and how to implement them.\n",
      "\n",
      "---\n",
      "\n",
      "### Why is Image Preprocessing Important?\n",
      "\n",
      "Raw images often come with:\n",
      "*   **Varying sizes and aspect ratios:** Models usually require fixed-size inputs.\n",
      "*   **Different lighting conditions:** Can make features hard to detect.\n",
      "*   **Noise and artifacts:** Scratches, dust, sensor noise, compression artifacts.\n",
      "*   **Irrelevant backgrounds:** May distract the model.\n",
      "*   **Inconsistent orientations:** Objects might be rotated or flipped.\n",
      "*   **High dimensionality:** RGB images have three channels, which can be computationally intensive.\n",
      "\n",
      "Preprocessing addresses these issues, leading to faster training, better accuracy, and improved robustness of your models.\n",
      "\n",
      "---\n",
      "\n",
      "### Common Image Preprocessing Techniques\n",
      "\n",
      "Let's categorize the techniques for clarity:\n",
      "\n",
      "#### 1. Geometric Transformations\n",
      "\n",
      "These deal with the size, position, and orientation of objects in an image.\n",
      "\n",
      "*   **Resizing/Scaling:**\n",
      "    *   **Purpose:** To make all images a consistent input size for the model.\n",
      "    *   **How:** Downsampling (shrinking) or upsampling (enlarging) an image to a target width and height. You need to choose an interpolation method (e.g., `cv2.INTER_AREA` for shrinking, `cv2.INTER_CUBIC` or `cv2.INTER_LINEAR` for enlarging).\n",
      "    *   **Considerations:** Can distort aspect ratio if not handled carefully (e.g., resize to square vs. resize shortest side and then crop).\n",
      "\n",
      "*   **Cropping:**\n",
      "    *   **Purpose:** To extract a Region of Interest (ROI) or remove irrelevant borders.\n",
      "    *   **How:** Selecting a rectangular portion of the image. Common types include center crop, random crop (for data augmentation), or cropping based on bounding box annotations.\n",
      "\n",
      "*   **Padding:**\n",
      "    *   **Purpose:** To add extra pixels around the image, often used to maintain aspect ratio during resizing or to make images a specific size without cropping.\n",
      "    *   **How:** Adding pixels (e.g., black, white, replicated edge pixels) symmetrically or asymmetrically around the image border.\n",
      "\n",
      "*   **Rotation:**\n",
      "    *   **Purpose:** To change the orientation of the image, useful for data augmentation.\n",
      "    *   **How:** Rotating the image by a certain angle around a central point.\n",
      "\n",
      "*   **Translation (Shifting):**\n",
      "    *   **Purpose:** To shift the image horizontally or vertically, also used for data augmentation.\n",
      "    *   **How:** Moving the image pixels by a fixed offset in X and Y directions.\n",
      "\n",
      "*   **Flipping:**\n",
      "    *   **Purpose:** To mirror the image horizontally or vertically, a common data augmentation technique for symmetrical objects.\n",
      "    *   **How:** Reflecting pixel values across an axis.\n",
      "\n",
      "#### 2. Pixel Value Transformations / Color Space Manipulation\n",
      "\n",
      "These deal with the intensity and color information of pixels.\n",
      "\n",
      "*   **Normalization/Standardization:**\n",
      "    *   **Purpose:** To scale pixel values to a specific range (e.g., 0-1, or -1-1) or to have zero mean and unit variance. This is crucial for neural networks, as it helps with faster convergence and prevents gradients from exploding/vanishing.\n",
      "    *   **How:**\n",
      "        *   **Min-Max Scaling:** `pixel_value = (pixel_value - min_val) / (max_val - min_val)`. For 8-bit images (0-255), this often simplifies to `pixel_value / 255.0`.\n",
      "        *   **Z-score Standardization:** `pixel_value = (pixel_value - mean) / std_dev`. Mean and std_dev are typically calculated over the entire dataset.\n",
      "\n",
      "*   **Grayscale Conversion:**\n",
      "    *   **Purpose:** To reduce the number of color channels (from 3 for RGB to 1 for grayscale), reducing dimensionality and computational cost, especially if color information isn't critical for the task.\n",
      "    *   **How:** Converting RGB channels to a single intensity channel (e.g., `0.2989*R + 0.5870*G + 0.1140*B`).\n",
      "\n",
      "*   **Brightness and Contrast Adjustment:**\n",
      "    *   **Purpose:** To correct for poor lighting conditions or enhance feature visibility.\n",
      "    *   **How:**\n",
      "        *   **Brightness:** Adding or subtracting a constant value from pixel intensities.\n",
      "        *   **Contrast:** Multiplying pixel intensities by a factor.\n",
      "        *   **Histogram Equalization (and CLAHE):** Redistributes pixel intensities to make the image contrast higher across its entire range. CLAHE (Contrast Limited Adaptive Histogram Equalization) is more robust as it operates on small regions.\n",
      "        *   **Gamma Correction:** Adjusts the overall brightness and contrast by a non-linear transformation, useful for images captured under different gamma encodings.\n",
      "\n",
      "#### 3. Noise Reduction and Feature Enhancement\n",
      "\n",
      "These techniques aim to clean up images or highlight specific features.\n",
      "\n",
      "*   **Denoising (Filtering):**\n",
      "    *   **Purpose:** To remove unwanted noise (e.g., Gaussian noise, salt-and-pepper noise) that can interfere with feature extraction.\n",
      "    *   **How:**\n",
      "        *   **Gaussian Blur:** Applies a Gaussian kernel to smooth the image and reduce noise, but can also blur edges.\n",
      "        *   **Median Blur:** Effective for salt-and-pepper noise, replaces each pixel's value with the median of its neighbors. Preserves edges better than Gaussian for this type of noise.\n",
      "        *   **Bilateral Filter:** A non-linear filter that smooths images while preserving strong edges.\n",
      "\n",
      "*   **Edge Detection:**\n",
      "    *   **Purpose:** To identify boundaries of objects in an image. Useful for segmentation or object localization tasks.\n",
      "    *   **How:** Algorithms like Canny, Sobel, Prewitt, or Laplacian use gradients to find sudden changes in pixel intensity.\n",
      "\n",
      "*   **Thresholding:**\n",
      "    *   **Purpose:** To convert a grayscale image into a binary image (black and white) based on a pixel intensity threshold. Useful for segmenting objects from the background.\n",
      "    *   **How:**\n",
      "        *   **Simple Thresholding:** All pixels above a certain value become white, others black.\n",
      "        *   **Adaptive Thresholding:** Calculates the threshold for smaller regions of the image, useful for varying lighting conditions.\n",
      "        *   **Otsu's Binarization:** Automatically determines an optimal global threshold.\n",
      "\n",
      "*   **Morphological Operations:**\n",
      "    *   **Purpose:** To process images based on their shapes (e.g., removing small objects, filling small holes, finding boundaries).\n",
      "    *   **How:** Operations like Erosion, Dilation, Opening, Closing, Gradient, Top Hat, Black Hat. They use a structuring element (kernel) to probe and modify the image.\n",
      "\n",
      "#### 4. Data Augmentation\n",
      "\n",
      "While technically a preprocessing step, it's often distinguished due to its primary purpose of expanding the dataset.\n",
      "\n",
      "*   **Purpose:** To artificially increase the size and diversity of the training dataset by creating modified versions of existing images. This helps models generalize better and reduces overfitting.\n",
      "*   **How:** Randomly applying combinations of the geometric and pixel value transformations mentioned above (e.g., random rotations, flips, shifts, zooms, brightness changes, color jitter). **Crucially, data augmentation is typically applied ONLY to the training data, not validation or test data.**\n",
      "\n",
      "---\n",
      "\n",
      "### How to Choose the Right Techniques\n",
      "\n",
      "1.  **Understand Your Task:**\n",
      "    *   **Classification:** Resizing, normalization, data augmentation are common.\n",
      "    *   **Object Detection/Segmentation:** Similar to classification, but pay attention to how bounding boxes/masks are transformed along with the image.\n",
      "    *   **OCR:** Binarization, noise reduction, deskewing (correcting tilt) are critical.\n",
      "\n",
      "2.  **Analyze Your Dataset:**\n",
      "    *   **Noise Level:** Do you need strong denoising?\n",
      "    *   **Lighting:** Is histogram equalization or gamma correction necessary?\n",
      "    *   **Resolution/Scale:** Are all objects similar sizes, or do you need to handle scale variations?\n",
      "    *   **Color Importance:** Is color crucial, or can you use grayscale?\n",
      "    *   **Variability:** How much natural variation exists (orientation, position)? This dictates augmentation needs.\n",
      "\n",
      "3.  **Model Requirements:**\n",
      "    *   **Input Size:** All models require a specific input shape (e.g., 224x224, 300x300).\n",
      "    *   **Input Range:** Neural networks often expect normalized inputs (0-1 or -1-1).\n",
      "    *   **Color Channels:** RGB vs. Grayscale.\n",
      "\n",
      "4.  **Experimentation:** Often, the best set of preprocessing steps is found through trial and error, evaluating model performance with different combinations.\n",
      "\n",
      "---\n",
      "\n",
      "### Implementation with Python Libraries\n",
      "\n",
      "The most popular libraries for image preprocessing in Python are:\n",
      "\n",
      "*   **OpenCV (`cv2`):** Highly optimized C++ library with Python bindings for a wide range of image processing functions.\n",
      "*   **Pillow (`PIL`):** Fundamental library for basic image manipulation (open, save, resize, crop, rotate).\n",
      "*   **Scikit-image (`skimage`):** Collection of algorithms for image processing, including advanced filtering, segmentation, and morphology.\n",
      "*   **NumPy:** Essential for array manipulation, forms the backbone for all these libraries.\n",
      "*   **TensorFlow/Keras (`tf.image`, `ImageDataGenerator`):** Built-in functions for preprocessing and augmentation specifically for deep learning models.\n",
      "*   **PyTorch (`torchvision.transforms`):** Similar to Keras, provides a powerful set of transformations for PyTorch models.\n",
      "\n",
      "---\n",
      "\n",
      "### Example: Basic Preprocessing Pipeline (OpenCV & NumPy)\n",
      "\n",
      "```python\n",
      "import cv2\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def preprocess_image(image_path, target_size=(224, 224)):\n",
      "    # 1. Load the image\n",
      "    img = cv2.imread(image_path)\n",
      "    if img is None:\n",
      "        print(f\"Error: Could not load image from {image_path}\")\n",
      "        return None\n",
      "\n",
      "    # Convert BGR to RGB (OpenCV loads in BGR by default)\n",
      "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
      "\n",
      "    # 2. Resize the image\n",
      "    # We'll use INTER_AREA for downsampling (shrinking)\n",
      "    # You might want to pad if aspect ratio is critical before resizing to a square\n",
      "    resized_img = cv2.resize(img_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
      "\n",
      "    # 3. Grayscale Conversion (Optional, uncomment if needed)\n",
      "    # gray_img = cv2.cvtColor(resized_img, cv2.COLOR_RGB2GRAY)\n",
      "    # # If converting to grayscale, you might want to reshape to (H, W, 1) for some models\n",
      "    # # gray_img = np.expand_dims(gray_img, axis=-1)\n",
      "    # processed_img = gray_img\n",
      "\n",
      "    processed_img = resized_img # Using RGB for now\n",
      "\n",
      "    # 4. Normalization (Min-Max scaling to 0-1 range)\n",
      "    normalized_img = processed_img.astype(np.float32) / 255.0\n",
      "\n",
      "    # 5. Noise Reduction (Optional, e.g., Gaussian Blur)\n",
      "    # blurred_img = cv2.GaussianBlur(normalized_img, (5, 5), 0)\n",
      "    # processed_img = blurred_img\n",
      "\n",
      "    # 6. Contrast Enhancement (Optional, e.g., CLAHE on grayscale)\n",
      "    # if processed_img.ndim == 2: # Check if it's grayscale\n",
      "    #     clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
      "    #     clahe_img = clahe.apply((processed_img * 255).astype(np.uint8)) # CLAHE expects uint8\n",
      "    #     processed_img = clahe_img.astype(np.float32) / 255.0\n",
      "\n",
      "    return normalized_img\n",
      "\n",
      "# --- Example Usage ---\n",
      "# Create a dummy image for demonstration\n",
      "dummy_image_path = 'dummy_image.jpg'\n",
      "dummy_image = np.random.randint(0, 256, (400, 600, 3), dtype=np.uint8)\n",
      "cv2.imwrite(dummy_image_path, cv2.cvtColor(dummy_image, cv2.COLOR_RGB2BGR))\n",
      "\n",
      "original_image = cv2.imread(dummy_image_path)\n",
      "original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
      "\n",
      "processed_image = preprocess_image(dummy_image_path, target_size=(150, 150))\n",
      "\n",
      "if processed_image is not None:\n",
      "    plt.figure(figsize=(10, 5))\n",
      "\n",
      "    plt.subplot(1, 2, 1)\n",
      "    plt.imshow(original_image_rgb)\n",
      "    plt.title(f\"Original Image\\nShape: {original_image_rgb.shape}\")\n",
      "    plt.axis('off')\n",
      "\n",
      "    plt.subplot(1, 2, 2)\n",
      "    plt.imshow(processed_image)\n",
      "    plt.title(f\"Processed Image\\nShape: {processed_image.shape}\\nValues: {processed_image.min():.2f}-{processed_image.max():.2f}\")\n",
      "    plt.axis('off')\n",
      "\n",
      "    plt.show()\n",
      "\n",
      "    # If you want to save the processed image (e.g., for inspection)\n",
      "    # cv2.imwrite('processed_dummy_image.png', (processed_image * 255).astype(np.uint8)[:, :, ::-1]) # Convert back to BGR for saving\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Best Practices\n",
      "\n",
      "*   **Consistency:** Apply the *exact same* preprocessing steps (excluding data augmentation) to your training, validation, and test datasets.\n",
      "*   **Order Matters:** The sequence of preprocessing steps can significantly impact the outcome (e.g., denoise *before* edge detection).\n",
      "*   **Avoid Over-Processing:** Don't remove useful information or introduce artifacts by applying too many or inappropriate transformations.\n",
      "*   **Inspect Results:** Always visualize your preprocessed images to ensure the transformations are having the desired effect.\n",
      "*   **Data Augmentation:** Only apply to training data. For evaluation, use the standard preprocessing steps.\n",
      "*   **Computational Cost:** Be mindful of the computational resources, especially for large datasets. Some operations can be intensive.\n",
      "\n",
      "By carefully selecting and applying the right image preprocessing techniques, you can significantly improve the performance and robustness of your computer vision models.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    print(\"Error: GOOGLE_API_KEY tidak ditemukan.\")\n",
    "    print(\"Pastikan file .env ada dan berisi GOOGLE_API_KEY=...\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=api_key) \n",
    "\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
